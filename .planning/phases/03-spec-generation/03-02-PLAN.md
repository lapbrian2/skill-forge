# Plan 03-02: System Prompt Engineering & Spec Quality

## Goal
Deeply engineer the spec generation system prompt to produce specific, buildable, terminology-consistent specs with few-shot examples. This is the product's secret sauce.

## Context
- Current SYSTEM_GENERATOR prompt is basic — needs to be deeply engineered
- Current promptGenerateSpec() is functional but lacks:
  - Few-shot examples of good vs bad specificity (SPEC-05)
  - User terminology echoing (SPEC-04)
  - Structured section-by-section generation guidance
- The quality of the generated spec IS the product. This prompt determines everything.

## Wave 1: System Prompt Overhaul

### Task 1.1: Rewrite SYSTEM_GENERATOR in prompts.ts
Complete rewrite of the spec generation system prompt:

**Core principles to encode:**
1. **Specificity over generality**: Every field must have a type, every endpoint a contract, every error a code
2. **User's terminology first**: The spec must use the exact terms the user used during discovery
3. **Assumption marking**: Any inferred detail not explicitly stated by user gets [ASSUMPTION] tag
4. **No weasel words**: Hard-ban list of vague terms — provide the specific alternatives
5. **Cascading consistency**: Entity names in data model MUST match API contracts MUST match user flows
6. **Buildability test**: "Could a developer implement this section in code without asking a single clarifying question?"

**Prompt structure:**
```
Role: Senior systems architect at a company that ships engineering specs to dev teams and AI coding agents

Context: You are generating a spec that will be copy-pasted directly into Claude Code or given to a development team. There is NO opportunity to ask follow-up questions. The spec must be self-contained and complete.

Quality bars:
- Every data model field: name, type, required/optional, constraints, default value, example
- Every API endpoint: method, path, auth requirement, request body (with types), response body (with types), all error codes with messages
- Every user flow: numbered steps, decision points, error recovery paths
- Every feature: acceptance criteria, edge cases, error handling

Anti-patterns to NEVER use:
[List of 20+ banned phrases with their specific replacements]

Structural rules:
- H1 for document title only
- H2 for major sections (numbered: ## 1. Product Overview)
- H3 for subsections (numbered: ### 1.1 Product Brief)
- Tables for structured data (feature matrices, field definitions, endpoint specs)
- Fenced code blocks for data models, API examples, config
- Mermaid-compatible text diagrams for architecture and flows
```

### Task 1.2: Rewrite promptGenerateSpec() with few-shot examples
Enhance the spec generation prompt template:

**Add few-shot examples per section type:**
- Data model: Show a GOOD example (specific types, constraints, indexes) vs BAD (vague descriptions)
- API endpoint: Show a GOOD example (full contract) vs BAD (just "handles requests")
- User flow: Show a GOOD example (numbered steps with error paths) vs BAD (high-level description)
- Feature spec: Show a GOOD example (acceptance criteria + edge cases) vs BAD (just a name and description)

**Terminology injection:**
- Extract key terms from project.initial_description and discovery.answers
- Inject them into the prompt: "Use these exact terms throughout the spec: [terms]"
- This ensures the spec echoes the user's language

**Section-specific instructions:**
- Each section in the spec template gets a mini-prompt with exactly what to include
- Section 5 (Data Model): "For each entity, create a table with columns: Field | Type | Required | Constraints | Default | Description"
- Section 6 (API Spec): "For each endpoint, include: Method, Path, Auth, Headers, Request Body (TypeScript interface), Response Body (TypeScript interface), Error Codes (table)"

### Task 1.3: Add terminology extraction utility
Create `src/lib/spec/terminology.ts`:
- `extractTerminology(description: string, answers: QAEntry[]): string[]`
- Extracts domain-specific terms, proper nouns, and technical terms from user's input
- Filters out common English words
- Returns list of terms to inject into the spec prompt
- Used by promptGenerateSpec() to ensure user terminology echoing (SPEC-04)

## Wave 2: Enhanced Spec Generation API

### Task 2.1: Update `/api/generate/route.ts`
Enhance the generate route:
- Pass full discovery data (not just project_data summary) to the prompt
- Include extracted terminology in the prompt
- Add section count to response headers for progress tracking
- Increase max_tokens for complex specs (16384 for complex, 12288 for moderate, 8192 for simple)

### Task 2.2: Add spec validation pre-check
Before streaming the spec, do a quick validation of the input data:
- Check that discovery data has sufficient content for the complexity level
- If discovery data is sparse (e.g., user skipped), inject a warning into the prompt
- Return 400 if project has zero discovery answers (can't generate from nothing)

## Verification
- [ ] Generated spec uses user's exact terminology from discovery
- [ ] Generated spec has concrete data model with field types, constraints, and indexes
- [ ] Generated spec has full API contracts (not just endpoint names)
- [ ] Generated spec has numbered user flows with error paths
- [ ] No weasel words appear in generated spec (verify with WEASEL_WORDS list)
- [ ] [ASSUMPTION] tags appear where AI inferred details not explicitly stated
- [ ] Spec sections are numbered consistently (## 1. → ## 13.)
- [ ] Code blocks have language tags for syntax highlighting
- [ ] Build passes with no TypeScript errors
